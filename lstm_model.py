# -*- coding: utf-8 -*-
"""LSTM model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OzAfqSvoR9dzI00TUXQepCbsTRxTfelR
"""

# importing the libraries
import yfinance as yf
import matplotlib. pyplot as plt
import numpy as np
import pandas as pd
import matplotlib
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from tensorflow import keras
from keras import layers, Model
from keras. layers import LSTM, Dense, Dropout
from sklearn.model_selection import TimeSeriesSplit,train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib. dates as mandates
from sklearn.preprocessing import MinMaxScaler
from sklearn import linear_model
from keras import Sequential
from keras.layers import Dense
from keras.callbacks import EarlyStopping
from keras import optimizers
from keras.optimizers import Adam
from keras.models import load_model
from keras.layers import LSTM
import streamlit as st

st.title('stock trend predictor')

#data collection

start_date = '1980-12-12'
end_date = '2023-07-22'

user_input = st.text_input('Enter stock Ticker' , 'AAPL')
df = yf.download(user_input, start=start_date, end=end_date)
st.subheader('Data from 1980 - 2023')
st.write(df.describe())

#visualisations

st.subheader('Closing Price vs Time chart')
fig = plt.figure(figsize=(12,6))
plt.plot(df.Close)
st.pyplot(fig)


st.subheader('Closing Price vs Time chart with 200MA')
ma100 = df.Close.rolling(100).mean()
fig = plt.figure(figsize=(12,6))
plt.plot(ma100)
plt.plot(df.Close)
st.pyplot(fig)


st.subheader('Closing Price vs Time chart with 100MA and 200MA ')
ma100 = df.Close.rolling(100).mean()
ma200 = df.Close.rolling(200).mean()
fig = plt.figure(figsize=(12,6))
plt.plot(ma100)
plt.plot(ma200)
plt.plot(df.Close)
st.pyplot(fig)


# splitting dataset into training ans testing

data_training = pd.DataFrame(df['Close'][0:int(len(df)*0.7)])
data_testing = pd.DataFrame(df['Close'][int(len(df)*0.7):])


# Scaling of data between 0-1 using minmax scaler from sklearn
scaler = MinMaxScaler(feature_range = (0,1))

data_training_array = scaler.fit_transform(data_training)


#splitting data into x_traina dn y_train
x_train = []
y_train = []

for i in range(100 ,data_training_array.shape[0]):
    x_train.append(data_training_array[i-100 : i])
    y_train.append(data_training_array[i,0])


x_train,y_train = np.array(x_train) , np.array(y_train)


#load my model

model = load_model('LSTM_model.h5');

# for testing we need the data for past 100 days so wqe need to add past 100 days data from 7518th row!!

past_100_days = data_training.tail(100)

final_df = past_100_days.append(data_testing , ignore_index = True)

#scaling down the test data
input_data = scaler.fit_transform(final_df)


x_test = []
y_test = []

for i in range(100, input_data.shape[0]):
  x_test.append(input_data[i-100 : i])
  y_test.append(input_data[i,0])



x_test ,y_test = np.array(x_test) , np.array(y_test)

y_predict = model.predict(x_test);

scaler.scale_
scale_factor = 1/scaler[0]
y_predict = y_predict * scale_factor
y_test = y_test * scale_factor



#final graph

st.subheader('Predictions Vs Original')
plt.figure(figsize = (12,6))
plt.plot(y_test , 'g', label = 'Original Price')
plt.plot(y_predict , 'r' , label = 'Predicted Price')
plt.xlabel('Time')
plt.ylabel('Close_price')

plt.legend()
plt.show()

import math
from sklearn.metrics import mean_squared_error
math.sqrt(mean_squared_error(y_test,y_predict))